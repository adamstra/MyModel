{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamstra/MyModel/blob/main/SSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "N5c7HC_dSkuL",
        "outputId": "1405b9ac-adab-4eaa-ab32-c1d3a29ff44b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 1 : Séparer les données"
      ],
      "metadata": {
        "id": "niQPyexKlit9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a-qzIq6FSefm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "O1PcuGxwSefo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def split_dataset(images_dir, annotations_dir, output_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
        "    # Lister toutes les images\n",
        "    images = [f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "    # Mélanger les données de manière aléatoire\n",
        "    random.shuffle(images)\n",
        "\n",
        "    # Calcul des tailles pour chaque ensemble\n",
        "    total_images = len(images)\n",
        "    train_size = int(train_ratio * total_images)\n",
        "    val_size = int(val_ratio * total_images)\n",
        "\n",
        "    # Séparer les ensembles\n",
        "    train_images = images[:train_size]\n",
        "    val_images = images[train_size:train_size + val_size]\n",
        "    test_images = images[train_size + val_size:]\n",
        "\n",
        "    # Créer les répertoires de sortie\n",
        "    os.makedirs(os.path.join(output_dir, 'train/images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'train/annotations'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'val/images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'val/annotations'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'test/images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'test/annotations'), exist_ok=True)\n",
        "\n",
        "    # Copier les fichiers dans les répertoires respectifs\n",
        "    def copy_files(images_list, dest_dir):\n",
        "        for img in images_list:\n",
        "            shutil.copy(os.path.join(images_dir, img), os.path.join(dest_dir, 'images', img))\n",
        "            # Copier l'annotation correspondante\n",
        "            annotation_file = img.replace('.jpg', '.xml').replace('.png', '.xml')\n",
        "            shutil.copy(os.path.join(annotations_dir, annotation_file), os.path.join(dest_dir, 'annotations', annotation_file))\n",
        "\n",
        "    # Copier les fichiers dans les ensembles train, val, et test\n",
        "    copy_files(train_images, os.path.join(output_dir, 'train'))\n",
        "    copy_files(val_images, os.path.join(output_dir, 'val'))\n",
        "    copy_files(test_images, os.path.join(output_dir, 'test'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemple d'utilisation :\n",
        "split_dataset(\"/content/drive/MyDrive/data/train\", \"/content/drive/MyDrive/data/train\", \"/content/drive/MyDrive/Adama_Traore\")"
      ],
      "metadata": {
        "id": "L7nakVj0dIKN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 2 : Entraîner le modèle avec les données séparées"
      ],
      "metadata": {
        "id": "PMnqtAocllD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Étape 2 : Entraîner le modèle avec les données séparées\n",
        "# Après avoir divisé les données, vous pouvez utiliser les ensembles train et val pour entraîner le modèle et ajuster les hyperparamètres.\n",
        "\n",
        "# Après avoir divisé les données, vous pouvez utiliser les ensembles train et val pour entraîner le modèle et ajuster les hyperparamètres.\n",
        "# Ici, vous devriez remplacer ce commentaire par le code d'entraînement de votre modèle.\n",
        "# Par exemple, si vous utilisez TensorFlow/Keras, vous pouvez utiliser le code suivant:\n",
        "\n",
        "\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# # Créer un générateur de données pour l'entraînement\n",
        "# train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#         '/content/drive/MyDrive/Adama_Traore/train',\n",
        "#         target_size=(150, 150),\n",
        "#         batch_size=32,\n",
        "#         class_mode='binary')\n",
        "\n",
        "# # Créer un générateur de données pour la validation\n",
        "# val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "# val_generator = val_datagen.flow_from_directory(\n",
        "#         '/content/drive/MyDrive/Adama_Traore/val',\n",
        "#         target_size=(150, 150),\n",
        "#         batch_size=32,\n",
        "#         class_mode='binary')\n",
        "\n",
        "# # Créer le modèle\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# # Compiler le modèle\n",
        "# model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "# # Entraîner le modèle\n",
        "# model.fit(\n",
        "#         train_generator,\n",
        "#         steps_per_epoch=2000,\n",
        "#         epochs=3,\n",
        "#         validation_data=val_generator,\n",
        "#         validation_steps=800)\n",
        "\n",
        "\n",
        "# # Enregistrez le modèle entraîné\n",
        "# model.save('/content/drive/MyDrive/my_model.h5')"
      ],
      "metadata": {
        "id": "LK_0b1yMeETi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "jOh-670qmKF2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer un générateur de données pour l'entraînement\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Adama_Traore/train',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Créer un générateur de données pour la validation\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Adama_Traore/val',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "D9Axw9jomMWe",
        "outputId": "335f978e-0c08-474f-d559-46136252b1d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 737 images belonging to 2 classes.\n",
            "Found 158 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer le modèle\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(16, activation='softmax'))"
      ],
      "metadata": {
        "id": "M2KaBmrdm9qh",
        "outputId": "94ae115d-77e6-4921-d192-4fb21296cd96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiler le modèle\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "v9V-4B4gnO9A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraîner le modèle\n",
        "model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=2000,\n",
        "        epochs=3,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=800)\n",
        "\n",
        "\n",
        "# Enregistrez le modèle entraîné\n",
        "model.save('/content/drive/MyDrive/my_model.h5')"
      ],
      "metadata": {
        "id": "61Zre8DNnXSm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}