{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamstra/MyModel/blob/main/VGG-16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ShiF5c4L6I3U",
        "outputId": "ea4d18fe-8484-41ac-dd71-14e5b0abe0c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: unzipper ce ficher le path: /content/drive/MyDrive/MyData.zip\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/MyData.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/MyDrive/data')"
      ],
      "metadata": {
        "id": "DQZxEjBO6Us2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Reshape\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "ZRWfR5hj65lY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_annotations(annotation_path):\n",
        "    \"\"\"Charge les annotations à partir d'un fichier XML Pascal VOC.\"\"\"\n",
        "    tree = ET.parse(annotation_path)\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "    for obj in root.iter('object'):\n",
        "        bndbox = obj.find('bndbox')\n",
        "        box = [\n",
        "            int(bndbox.find('xmin').text),\n",
        "            int(bndbox.find('ymin').text),\n",
        "            int(bndbox.find('xmax').text),\n",
        "            int(bndbox.find('ymax').text)\n",
        "        ]\n",
        "        boxes.append(box)\n",
        "    return np.array(boxes)"
      ],
      "metadata": {
        "id": "2LiEYWcR7RTS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(image_dir):\n",
        "    \"\"\"Charge les images et leurs annotations.\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith('.jpg'):\n",
        "            img_path = os.path.join(image_dir, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (224, 224))  # Redimensionner les images pour qu'elles soient compatibles avec VGG16\n",
        "            xml_path = img_path.replace('.jpg', '.xml')\n",
        "            boxes = load_annotations(xml_path)  # Charger les annotations\n",
        "            images.append(img)\n",
        "            labels.append(boxes)\n",
        "\n",
        "    return np.array(images), labels"
      ],
      "metadata": {
        "id": "TopxwyhO7pCS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Charger et séparer les données en train/validation (80% / 20%)\n",
        "image_dir = '/content/drive/MyDrive/data'\n",
        "images, labels = load_data(image_dir)\n",
        "\n",
        "# 3. Fixer une limite de nombre de bounding boxes par image (par ex: 5 max)\n",
        "max_boxes = 10\n",
        "def pad_bounding_boxes(boxes):\n",
        "    \"\"\"Ajoute du padding si une image a moins de 'max_boxes' bounding boxes.\n",
        "    Tronque si une image a plus de 'max_boxes' bounding boxes.\"\"\"\n",
        "    padded_boxes = np.zeros((max_boxes, 4))  # Créer un tableau vide pour max_boxes bounding boxes\n",
        "    num_boxes = min(len(boxes), max_boxes)  # Prendre le minimum entre le nombre de boxes et max_boxes\n",
        "    padded_boxes[:num_boxes] = boxes[:num_boxes]  # Remplir avec les vraies bounding boxes, tronquées si nécessaire\n",
        "    return padded_boxes\n",
        "\n",
        "padded_labels = [pad_bounding_boxes(box) for box in labels]"
      ],
      "metadata": {
        "id": "P-4-IkO67vwz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Séparer en train et validation\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(images, padded_labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UHjKsp_a70gH",
        "outputId": "43e53e72-39f9-4872-c6a5-bee26f76152c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-af0998c2ac74>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 4. Séparer en train et validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2785\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2786\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2787\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2416\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Créer un dataset TensorFlow avec padding pour les bounding boxes\n",
        "def process_data(images, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    return dataset.map(lambda x, y: (tf.image.convert_image_dtype(x, tf.float32), y))"
      ],
      "metadata": {
        "id": "8O7UP77k8UGd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Créer des datasets train/validation\n",
        "train_dataset = process_data(train_images, train_labels).batch(32)\n",
        "val_dataset = process_data(val_images, val_labels).batch(32)"
      ],
      "metadata": {
        "id": "HYKmV0gP8Y_W",
        "outputId": "c551df4f-e60a-49ab-a0ec-8e708fb33849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0ae027a69fe1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 6. Créer des datasets train/validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Définir et construire le modèle VGG16 pour la détection d'objets\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Geler les couches du modèle de base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "8mvGbRW78cOo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajouter des couches fully-connected\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "# Assuming your target labels are flattened (40 values for 10 objects)\n",
        "# Reshape the output layer to match the target shape [?, 40] for 10 objects with 4 coordinates\n",
        "output = Dense(40, activation='linear')(x)\n",
        "output = Reshape((10, 4))(output)  # Reshape to (10, 4)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "YMFVk5IZ9MT0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Compilation du modèle\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2k_5T7Ow9ZAO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Ajouter un callback pour sauvegarder les checkpoints du meilleur modèle\n",
        "checkpoint_filepath = '/kaggle/working/checkpoints/vgg16_checkpoint.keras' # Change the file extension to .keras\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_best_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "7mgDflYT9dm_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Entraîner le modèle avec validation et sauvegarde des checkpoints\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10,\n",
        "    steps_per_epoch=len(train_images) // 32,\n",
        "    validation_steps=len(val_images) // 32,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "uU4-URKK9ian",
        "outputId": "f6a4808a-bc3a-46fe-847d-f417c80aa003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m 1/26\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:32\u001b[0m 23s/step - accuracy: 0.2313 - loss: 70385.8672"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5kMaD_-m-E6A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}