{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "74YfEhVEKIQs",
        "outputId": "0a05f917-5344-4e40-c381-827e4ecd2493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-CUI9SyHKCWh",
        "outputId": "62164b70-846a-468c-a9fd-664490da2609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.20 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Configuration des hyperparamètres\n",
        "BATCH_SIZE = 4\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE = 0.005\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "pu3qMjBzLVCZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Définir le Dataset personnalisé\n",
        "class PascalVOCDataset(Dataset):\n",
        "    def __init__(self, root_dir, transforms=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transforms = transforms\n",
        "        self.imgs = [f for f in os.listdir(root_dir) if f.endswith(\".jpg\")]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_dir, self.imgs[idx])\n",
        "        annot_path = img_path.replace(\".jpg\", \".xml\")\n",
        "\n",
        "        # Chargement de l'image\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Lecture des annotations\n",
        "        tree = ET.parse(annot_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for obj in root.findall(\"object\"):\n",
        "            bbox = obj.find(\"bndbox\")\n",
        "            xmin = int(bbox.find(\"xmin\").text)\n",
        "            ymin = int(bbox.find(\"ymin\").text)\n",
        "            xmax = int(bbox.find(\"xmax\").text)\n",
        "            ymax = int(bbox.find(\"ymax\").text)\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(1)  # Assuming a single class of objects\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        image_id = torch.tensor([idx])\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"image_id\": image_id,\n",
        "        }\n",
        "\n",
        "        if self.transforms:\n",
        "            transformed = self.transforms(image=np.array(img))\n",
        "            img = transformed[\"image\"]\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "R1qZXqqSLafj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Data Augmentation avec Albumentations\n",
        "train_transforms = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.ShiftScaleRotate(scale_limit=0.2, rotate_limit=15, p=0.5),\n",
        "    A.Normalize(), # Apply normalization before converting to tensor\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Initialisation du dataset\n",
        "train_dataset = PascalVOCDataset(root_dir=\"/content/drive/MyDrive/data/train\", transforms=train_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n"
      ],
      "metadata": {
        "id": "TX2k1VPOLpoE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Initialisation du modèle Faster R-CNN\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "num_classes = 16  # Background + single object class\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "model.to(DEVICE)"
      ],
      "metadata": {
        "id": "3PFJPCY2LxM6",
        "outputId": "46247c56-dcef-4142-fef5-3b302780ac90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|██████████| 160M/160M [00:01<00:00, 124MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=16, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=64, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Définition de l'optimiseur et du scheduler\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ],
      "metadata": {
        "id": "0bs_8-4cL9sQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Fonction d'entraînement\n",
        "def train_one_epoch(model, optimizer, data_loader, device):\n",
        "    model.train()\n",
        "    for images, targets in data_loader:\n",
        "        images = list(img.to(device) for img in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "f2bMUDI0MEoR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Entraînement du modèle\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_one_epoch(model, optimizer, train_loader, DEVICE)\n",
        "    lr_scheduler.step()\n",
        "    print(f\"Epoch {epoch+1} completed\")\n",
        "\n",
        "# Step 8: Évaluation (simple accuracy check)\n",
        "model.eval()\n",
        "# Evaluation logic could include IoU calculations or mAP evaluation here\n",
        "\n",
        "torch.save(model.state_dict(), \"faster_rcnn_trained.pth\")\n",
        "print(\"Training complete and model saved.\")"
      ],
      "metadata": {
        "id": "_5_aixuYMJVH",
        "outputId": "fa18811d-5ba8-46b5-f668-6fa010ef4780",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed\n",
            "Epoch 2 completed\n",
            "Epoch 3 completed\n",
            "Epoch 4 completed\n",
            "Epoch 5 completed\n",
            "Epoch 6 completed\n",
            "Epoch 7 completed\n",
            "Epoch 8 completed\n",
            "Epoch 9 completed\n",
            "Epoch 10 completed\n",
            "Epoch 11 completed\n",
            "Epoch 12 completed\n",
            "Epoch 13 completed\n",
            "Epoch 14 completed\n",
            "Epoch 15 completed\n",
            "Epoch 16 completed\n",
            "Epoch 17 completed\n",
            "Epoch 18 completed\n",
            "Epoch 19 completed\n",
            "Epoch 20 completed\n",
            "Epoch 21 completed\n",
            "Epoch 22 completed\n",
            "Epoch 23 completed\n",
            "Epoch 24 completed\n",
            "Epoch 25 completed\n",
            "Epoch 26 completed\n",
            "Epoch 27 completed\n",
            "Epoch 28 completed\n",
            "Epoch 29 completed\n",
            "Epoch 30 completed\n",
            "Training complete and model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Évaluation (simple accuracy check)\n",
        "model.eval()\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, targets in train_loader:\n",
        "    images = list(img.to(DEVICE) for img in images)\n",
        "    targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
        "    outputs = model(images)\n",
        "\n",
        "    for output, target in zip(outputs, targets):\n",
        "      # Get predicted labels and scores\n",
        "      predicted_labels = output['labels'].cpu().numpy()\n",
        "      predicted_scores = output['scores'].cpu().numpy()\n",
        "\n",
        "      # Filter predictions based on a score threshold (e.g., 0.5)\n",
        "      # This helps to reduce the number of false positive predictions\n",
        "      score_threshold = 0.5\n",
        "      filtered_indices = predicted_scores >= score_threshold\n",
        "      predicted_labels = predicted_labels[filtered_indices]\n",
        "\n",
        "      true_labels = target['labels'].cpu().numpy()\n",
        "\n",
        "      # Now compare the filtered predicted labels with the true labels\n",
        "      # Consider only the common elements for comparison to handle the shape mismatch\n",
        "      num_common_elements = min(len(predicted_labels), len(true_labels))\n",
        "      correct_predictions += np.sum(predicted_labels[:num_common_elements] == true_labels[:num_common_elements])\n",
        "      total_predictions += len(true_labels)\n",
        "\n",
        "accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "# You can add more evaluation metrics (e.g., mAP, IoU) here."
      ],
      "metadata": {
        "id": "eC_n9SUjMkhg",
        "outputId": "a5159fa3-e938-454a-8b7f-a3ec16acd3ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OGkbaicVoHXz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}